{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train models\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load in data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from typing import List\n",
    "import tensorflow as tf\n",
    "import torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get list of all files in a directory\n",
    "def get_list_of_files_in_directory(directory: str) -> List[str]:\n",
    "    \"\"\"return list of all files in a directory\n",
    "    Args:\n",
    "        directory (str): string of directory\n",
    "\n",
    "    Returns:\n",
    "        List[str]: list of all files in a directory\n",
    "    \"\"\"    \n",
    "    list_of_files = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(directory):\n",
    "        list_of_files += [os.path.join(dirpath, file) for file in filenames]\n",
    "    return list_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list for noise and rat files\n",
    "noise_files = get_list_of_files_in_directory(r'C:\\Users\\gijst\\Documents\\Master Data Science\\Thesis\\processed_data\\noise')\n",
    "rat_files = get_list_of_files_in_directory(r'C:\\Users\\gijst\\Documents\\Master Data Science\\Thesis\\processed_data\\rats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that loads in pickle data from a list of files, keeps file data separate\n",
    "def load_in_data_from_list_of_files(list_of_files: List[str]) -> List[pd.DataFrame]:\n",
    "    \"\"\"load in data from list of files\n",
    "    Args:\n",
    "        list_of_files (List[str]): list of files\n",
    "\n",
    "    Returns:\n",
    "        List[pd.DataFrame]: list of data\n",
    "    \"\"\"    \n",
    "    list_of_data = []\n",
    "    for file in list_of_files:\n",
    "        data = pd.read_pickle(file)\n",
    "        list_of_data.append(data)\n",
    "    return list_of_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = load_in_data_from_list_of_files(noise_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that loads in pickle data from a list of files and creates tensorflow dataset, keeps file data separate\n",
    "def load_in_data_from_list_of_files_and_create_tf_dataset(list_of_files: List[str]) -> tf.data.Dataset:\n",
    "    \"\"\"load in data from list of files and create tensorflow dataset\n",
    "    Args:\n",
    "        list_of_files (List[str]): list of files\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: tensorflow dataset\n",
    "    \"\"\"    \n",
    "    list_of_data = []\n",
    "    for file in list_of_files:\n",
    "        data = pd.read_pickle(file)\n",
    "        # for each mfcc column, create a tf object\n",
    "        for column in data.columns:\n",
    "            print(column)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(list_of_data)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m noise_df \u001b[39m=\u001b[39m load_in_data_from_list_of_files_and_create_tf_dataset(noise_files)\n",
      "Cell \u001b[1;32mIn[30], line 14\u001b[0m, in \u001b[0;36mload_in_data_from_list_of_files_and_create_tf_dataset\u001b[1;34m(list_of_files)\u001b[0m\n\u001b[0;32m     12\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(file)\n\u001b[0;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(data))\n\u001b[1;32m---> 14\u001b[0m data \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mconvert_to_tensor(data)\n\u001b[0;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(data))\n\u001b[0;32m     16\u001b[0m list_of_data\u001b[39m.\u001b[39mappend(data)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "noise_df = load_in_data_from_list_of_files_and_create_tf_dataset(noise_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that converts pandas DataFrame to tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc</th>\n",
       "      <th>mfcc_delta</th>\n",
       "      <th>mfcc_delta2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>[[-592.8254019790648, -571.0731381455644, -577...</td>\n",
       "      <td>[[1.3170128025803853, 1.3170128025803853, 1.31...</td>\n",
       "      <td>[[-0.16227823164650731, -0.16227823164650731, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.5</th>\n",
       "      <td>[[-608.7352391793245, -580.233915746532, -586....</td>\n",
       "      <td>[[4.3237974601227025, 4.3237974601227025, 4.32...</td>\n",
       "      <td>[[-0.308596079804532, -0.308596079804532, -0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45.0</th>\n",
       "      <td>[[-610.1032334783206, -582.771563666319, -583....</td>\n",
       "      <td>[[2.1310839732976103, 2.1310839732976103, 2.13...</td>\n",
       "      <td>[[-0.03104220387461283, -0.03104220387461283, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67.5</th>\n",
       "      <td>[[-610.0738890432665, -585.7126960778877, -582...</td>\n",
       "      <td>[[3.1996501819546754, 3.1996501819546754, 3.19...</td>\n",
       "      <td>[[-0.31727019419354974, -0.31727019419354974, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90.0</th>\n",
       "      <td>[[-627.0004865589998, -589.2692674552682, -579...</td>\n",
       "      <td>[[3.6681272967223713, 3.6681272967223713, 3.66...</td>\n",
       "      <td>[[-0.23270081633240927, -0.23270081633240927, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239872.5</th>\n",
       "      <td>[[-607.8207577822391, -586.9752884541805, -580...</td>\n",
       "      <td>[[2.221566666861387, 2.221566666861387, 2.2215...</td>\n",
       "      <td>[[0.05832850203105145, 0.05832850203105145, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239895.0</th>\n",
       "      <td>[[-594.1578438754578, -567.6026891429951, -577...</td>\n",
       "      <td>[[-0.36866502432704057, -0.36866502432704057, ...</td>\n",
       "      <td>[[-0.042164487816116696, -0.042164487816116696...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239917.5</th>\n",
       "      <td>[[-615.3976614950632, -581.9114434318839, -580...</td>\n",
       "      <td>[[1.3955381131212372, 1.3955381131212372, 1.39...</td>\n",
       "      <td>[[-0.26508166342842915, -0.26508166342842915, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239940.0</th>\n",
       "      <td>[[-629.0757996053932, -587.4078178431221, -578...</td>\n",
       "      <td>[[4.484890256833094, 4.484890256833094, 4.4848...</td>\n",
       "      <td>[[-0.2887694215981813, -0.2887694215981813, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239962.5</th>\n",
       "      <td>[[-623.4805290078729, -605.1371142668957, -602...</td>\n",
       "      <td>[[4.716596202047491, 4.716596202047491, 4.7165...</td>\n",
       "      <td>[[-0.35736709977986914, -0.35736709977986914, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10666 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       mfcc   \n",
       "0.0       [[-592.8254019790648, -571.0731381455644, -577...  \\\n",
       "22.5      [[-608.7352391793245, -580.233915746532, -586....   \n",
       "45.0      [[-610.1032334783206, -582.771563666319, -583....   \n",
       "67.5      [[-610.0738890432665, -585.7126960778877, -582...   \n",
       "90.0      [[-627.0004865589998, -589.2692674552682, -579...   \n",
       "...                                                     ...   \n",
       "239872.5  [[-607.8207577822391, -586.9752884541805, -580...   \n",
       "239895.0  [[-594.1578438754578, -567.6026891429951, -577...   \n",
       "239917.5  [[-615.3976614950632, -581.9114434318839, -580...   \n",
       "239940.0  [[-629.0757996053932, -587.4078178431221, -578...   \n",
       "239962.5  [[-623.4805290078729, -605.1371142668957, -602...   \n",
       "\n",
       "                                                 mfcc_delta   \n",
       "0.0       [[1.3170128025803853, 1.3170128025803853, 1.31...  \\\n",
       "22.5      [[4.3237974601227025, 4.3237974601227025, 4.32...   \n",
       "45.0      [[2.1310839732976103, 2.1310839732976103, 2.13...   \n",
       "67.5      [[3.1996501819546754, 3.1996501819546754, 3.19...   \n",
       "90.0      [[3.6681272967223713, 3.6681272967223713, 3.66...   \n",
       "...                                                     ...   \n",
       "239872.5  [[2.221566666861387, 2.221566666861387, 2.2215...   \n",
       "239895.0  [[-0.36866502432704057, -0.36866502432704057, ...   \n",
       "239917.5  [[1.3955381131212372, 1.3955381131212372, 1.39...   \n",
       "239940.0  [[4.484890256833094, 4.484890256833094, 4.4848...   \n",
       "239962.5  [[4.716596202047491, 4.716596202047491, 4.7165...   \n",
       "\n",
       "                                                mfcc_delta2  \n",
       "0.0       [[-0.16227823164650731, -0.16227823164650731, ...  \n",
       "22.5      [[-0.308596079804532, -0.308596079804532, -0.3...  \n",
       "45.0      [[-0.03104220387461283, -0.03104220387461283, ...  \n",
       "67.5      [[-0.31727019419354974, -0.31727019419354974, ...  \n",
       "90.0      [[-0.23270081633240927, -0.23270081633240927, ...  \n",
       "...                                                     ...  \n",
       "239872.5  [[0.05832850203105145, 0.05832850203105145, 0....  \n",
       "239895.0  [[-0.042164487816116696, -0.042164487816116696...  \n",
       "239917.5  [[-0.26508166342842915, -0.26508166342842915, ...  \n",
       "239940.0  [[-0.2887694215981813, -0.2887694215981813, -0...  \n",
       "239962.5  [[-0.35736709977986914, -0.35736709977986914, ...  \n",
       "\n",
       "[10666 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpytorch_lightning\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightning'"
     ]
    }
   ],
   "source": [
    "import lightning.pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
